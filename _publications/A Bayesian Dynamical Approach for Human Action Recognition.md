---
title: "A Bayesian Dynamical Approach for Human Action Recognition"
collection: publications
permalink: /publication/A Bayesian Dynamical Approach for Human Action Recognition
excerpt: "Short description of portfolio item number 1<br/><img src='/images/500x300.png'>"
date: 2021-08-16
venue: 'Sensors'
paperurl: 'http://academicpages.github.io/files/A Bayesian Dynamical Approach for Human Action Recognition.pdf'
citation: 'Farnoosh, A., Wang, Z., Zhu, S., & Ostadabbas, S. (2021). A bayesian dynamical approach for human action recognition. Sensors, 21(16), 5613.'
---

We introduce a generative Bayesian switching dynamical model for action recognition in 3D skeletal data. Our model encodes highly correlated skeletal data into a few sets of low-dimensional switching temporal processes and from there decodes to the motion data and their associated action labels. We parameterize these temporal processes with regard to a switching deep autoregressive prior to accommodate both multimodal and higher-order nonlinear inter-dependencies. This results in a dynamical deep generative latent model that parses meaningful intrinsic states in skeletal dynamics and enables action recognition. These sequences of states provide visual and quantitative interpretations about motion primitives that gave rise to each action class, which have not been explored previously. In contrast to previous works, which often overlook temporal dynamics, our method explicitly model temporal transitions and is generative. Our experiments on two large-scale 3D skeletal datasets substantiate the superior performance of our model in comparison with the state-of-the-art methods. Specifically, our method achieved 6.3% higher action classification accuracy (by incorporating a dynamical generative framework), and 3.5% better predictive error (by employing a nonlinear second-order dynamical transition model) when compared with the best-performing competitors.
